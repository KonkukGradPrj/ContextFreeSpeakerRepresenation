{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "95.3%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspace/ContextFreeSpeakerRepresenation/data/create_data.ipynb Cell 1\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f7175697a7a6963616c5f656e67656c62617274227d@ssh-remote%2B114.70.21.83/workspace/ContextFreeSpeakerRepresenation/data/create_data.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchaudio\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f7175697a7a6963616c5f656e67656c62617274227d@ssh-remote%2B114.70.21.83/workspace/ContextFreeSpeakerRepresenation/data/create_data.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Download the LIBRISPEECH dataset\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f7175697a7a6963616c5f656e67656c62617274227d@ssh-remote%2B114.70.21.83/workspace/ContextFreeSpeakerRepresenation/data/create_data.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m librispeech_dataset \u001b[39m=\u001b[39m torchaudio\u001b[39m.\u001b[39;49mdatasets\u001b[39m.\u001b[39;49mLIBRISPEECH(\u001b[39m\"\u001b[39;49m\u001b[39m./\u001b[39;49m\u001b[39m\"\u001b[39;49m, download\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchaudio/datasets/librispeech.py:113\u001b[0m, in \u001b[0;36mLIBRISPEECH.__init__\u001b[0;34m(self, root, url, folder_in_archive, download)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path):\n\u001b[1;32m    112\u001b[0m     \u001b[39mif\u001b[39;00m download:\n\u001b[0;32m--> 113\u001b[0m         _download_librispeech(root, url)\n\u001b[1;32m    114\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    116\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDataset not found at \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path\u001b[39m}\u001b[39;00m\u001b[39m. Please set `download=True` to download the dataset.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchaudio/datasets/librispeech.py:42\u001b[0m, in \u001b[0;36m_download_librispeech\u001b[0;34m(root, url)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(archive):\n\u001b[1;32m     41\u001b[0m     checksum \u001b[39m=\u001b[39m _CHECKSUMS\u001b[39m.\u001b[39mget(download_url, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m---> 42\u001b[0m     download_url_to_file(download_url, archive, hash_prefix\u001b[39m=\u001b[39;49mchecksum)\n\u001b[1;32m     43\u001b[0m _extract_tar(archive)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/hub.py:657\u001b[0m, in \u001b[0;36mdownload_url_to_file\u001b[0;34m(url, dst, hash_prefix, progress)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[39mif\u001b[39;00m hash_prefix \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    656\u001b[0m             sha256\u001b[39m.\u001b[39mupdate(buffer)\n\u001b[0;32m--> 657\u001b[0m         pbar\u001b[39m.\u001b[39;49mupdate(\u001b[39mlen\u001b[39;49m(buffer))\n\u001b[1;32m    659\u001b[0m f\u001b[39m.\u001b[39mclose()\n\u001b[1;32m    660\u001b[0m \u001b[39mif\u001b[39;00m hash_prefix \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/hub.py:39\u001b[0m, in \u001b[0;36m_Faketqdm.update\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     sys\u001b[39m.\u001b[39mstderr\u001b[39m.\u001b[39mwrite(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m{\u001b[39;00m\u001b[39m100\u001b[39m\u001b[39m \u001b[39m\u001b[39m*\u001b[39m\u001b[39m \u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39m\u001b[39mfloat\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal)\u001b[39m:\u001b[39;00m\u001b[39m.1f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m sys\u001b[39m.\u001b[39;49mstderr\u001b[39m.\u001b[39;49mflush()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/iostream.py:580\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpub_thread\u001b[39m.\u001b[39mschedule(evt\u001b[39m.\u001b[39mset)\n\u001b[1;32m    579\u001b[0m     \u001b[39m# and give a timeout to avoid\u001b[39;00m\n\u001b[0;32m--> 580\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt\u001b[39m.\u001b[39;49mwait(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mflush_timeout):\n\u001b[1;32m    581\u001b[0m         \u001b[39m# write directly to __stderr__ instead of warning because\u001b[39;00m\n\u001b[1;32m    582\u001b[0m         \u001b[39m# if this is happening sys.stderr may be the problem.\u001b[39;00m\n\u001b[1;32m    583\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mIOStream.flush timed out\u001b[39m\u001b[39m\"\u001b[39m, file\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39m__stderr__)\n\u001b[1;32m    584\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.8/threading.py:558\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    557\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 558\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    559\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.8/threading.py:306\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 306\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[1;32m    307\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "\n",
    "# Download the LIBRISPEECH dataset\n",
    "train_clean_360 = torchaudio.datasets.LIBRISPEECH(\"./clean\", url=\"train-clean-360\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "def get_random_utterance(dataset):\n",
    "    index = random.randint(0, len(dataset) - 1)\n",
    "    waveform, sample_rate, utterance, _, _, _ = dataset[index]\n",
    "    return waveform, sample_rate, utterance\n",
    "\n",
    "def get_random_pair(dataset):\n",
    "    source_waveform, sample_rate, source_utterance = get_random_utterance(dataset)\n",
    "    noise_waveform, _, _ = get_random_utterance(dataset)\n",
    "    return source_waveform, noise_waveform, sample_rate, source_utterance\n",
    "\n",
    "def mix_utterances(source_waveform, noise_waveform):\n",
    "    # Proportion of starting noise\n",
    "    overlap_start = 0.1\n",
    "    overlap_end = random.uniform(overlap_start, 1 - overlap_start)  # Adjusted the range\n",
    "    \n",
    "    # Determine the overlap percentage\n",
    "    overlap_percentage = overlap_end - overlap_start  # Adjusted the calculation\n",
    "    overlap_samples = int(overlap_percentage * source_waveform.shape[1])\n",
    "\n",
    "    # If noise is longer than source or overlap, crop noise\n",
    "    if overlap_samples < noise_waveform.shape[1]:\n",
    "        noise_waveform = noise_waveform[:, :overlap_samples]\n",
    "\n",
    "    # If noise is shorter than source or overlap, pad noise\n",
    "    if noise_waveform.shape[1] < overlap_samples:\n",
    "        padding = overlap_samples - noise_waveform.shape[1]\n",
    "        noise_waveform = torch.nn.functional.pad(noise_waveform, (0, padding))\n",
    "\n",
    "    # Mix the source and noise waveforms\n",
    "    start = random.randint(source_waveform.shape[1] // 10, source_waveform.shape[1] - overlap_samples)\n",
    "    end = start + overlap_samples\n",
    "    \n",
    "    # Scale the waveforms to prevent clipping\n",
    "    mixed_waveform = source_waveform.clone()\n",
    "    mixed_waveform[:, start:end] = (mixed_waveform[:, start:end] + noise_waveform[:, :overlap_samples]) / 2\n",
    "\n",
    "    return mixed_waveform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "\n",
    "# Initialize the dataset\n",
    "dataset_path = os.path.join(\".\")\n",
    "librispeech_dataset = torchaudio.datasets.LIBRISPEECH(dataset_path, download=True)\n",
    "\n",
    "output_dir = os.path.join(\".\", \"LIBRISPEECH2mix\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create a directory for training samples\n",
    "train_output_dir = os.path.join(\".\", \"LIBRISPEECH2mix\", \"train\")\n",
    "os.makedirs(train_output_dir, exist_ok=True)\n",
    "\n",
    "for i in range(100):  # assuming 100 training samples\n",
    "    source_waveform, noise_waveform, sample_rate, _ = get_random_pair(librispeech_dataset)\n",
    "    mixed_waveform = mix_utterances(source_waveform, noise_waveform)\n",
    "    \n",
    "    mixed_path = os.path.join(train_output_dir, f\"mixed_train_{i}.wav\")\n",
    "    torchaudio.save(mixed_path, mixed_waveform, sample_rate)\n",
    "    \n",
    "    source_path = os.path.join(train_output_dir, f\"source_train_{i}.wav\")\n",
    "    torchaudio.save(source_path, source_waveform, sample_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory for evaluation samples\n",
    "eval_output_dir = os.path.join(\".\", \"LIBRISPEECH2mix\", \"eval\")\n",
    "os.makedirs(eval_output_dir, exist_ok=True)\n",
    "\n",
    "for i in range(100):  # assuming 100 evaluation samples\n",
    "    source_waveform, noise_waveform, sample_rate, source_utterance = get_random_pair(librispeech_dataset)\n",
    "    mixed_waveform = mix_utterances(source_waveform, noise_waveform)\n",
    "    \n",
    "    mixed_path = os.path.join(eval_output_dir, f\"mixed_eval_{i}.wav\")\n",
    "    torchaudio.save(mixed_path, mixed_waveform, sample_rate)\n",
    "    \n",
    "    text_path = os.path.join(eval_output_dir, f\"mixed_eval_{i}.txt\")\n",
    "    with open(text_path, \"w\") as f:\n",
    "        f.write(source_utterance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
